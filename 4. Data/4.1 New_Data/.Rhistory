sum = sum + coredata(x[i,])
x[i,] = sum
}
return(x)
}
# Defining two functions to name data structures
NamingRows = function(String, data, startingValue) {
# Input Variables:
# String        = value in "" that will be the name that will be iterated
# data          = data structure that will have a new name for rows
# startingValue = allows to start with 0 or 1 etc...
dataNames = matrix("0", nrow = nrow(data), ncol = 1, byrow = TRUE)
for (i in 1:nrow(dataNames)) {
dataNames[i, ] = paste(String, i - 1 + startingValue, sep = "") # sep="" means that there is no space between w and the number
}
rownames(data) = c(dataNames)
return (data)
}
NamingCols = function(String, data, startingValue) {
dataNames = matrix("0", nrow = 1, ncol = ncol(data), byrow = TRUE)
for (i in 1:ncol(dataNames)) {
dataNames[, i] = paste(String, i - 1 + startingValue, sep = "") # sep="" means that there is no space between w and the number
}
colnames(data) = c(dataNames)
return (data)
}
library(xts)
library(zoo)
library(ggplot2)
library(TTR) #Technical Trading Rule
library(gridExtra) #Allow to place 2 graphs on the same grids
library(tseries)
library(readxl)
# Usefull functions: own code
BinominalEvolution = function (x){
for (i in 1:length(x)) {
if (i == length(x)) { # When we get to the last data entry, the output is always NA because we cannot compare it to a future value. Without this, there is an error message
x[i, ] = NA
} else if (is.na(x[i+1, ]) || is.na(x[i, ])) { # If comparing with a NA, the output is automatically NA.
x[i, ] = NA
} else if (coredata(x[i+1, ]) > coredata(x[i, ])) {
x[i, ] = 1
} else {
x[i, ] = 0
}
}
return (x)
}
WeightedMovingAverageTS = function (x, n) { # The function takes two inputs: x = the timeseries that is weighted, n = the amount of days of the weighting
divisor = 0
y = x
for (q in 1:n) { # This part calculates the divisor (i.e. the denominator of the weighted sum)
divisor = divisor + q
}
for (l in 1:length(x)) { # This part calculates the weighted sum
weightedSum = 0
if (l < n) {
y[l, ] = NA
} else {
for (i in 1:n) {
weightedSum = weightedSum + coredata(x[l - i + 1]) * (n - i + 1)
}
y[l, ] = weightedSum
}
}
return (y/divisor) # The function outputs a weighted timeseries
}
normalize <- function(x) {
return ((x - min(x))/(max(x) - min(x)))
}
CumulativeSum <- function(x) {
sum = 0
for (i in 1:nrow(x)) {
sum = sum + coredata(x[i,])
x[i,] = sum
}
return(x)
}
# Defining two functions to name data structures
NamingRows = function(String, data, startingValue) {
# Input Variables:
# String        = value in "" that will be the name that will be iterated
# data          = data structure that will have a new name for rows
# startingValue = allows to start with 0 or 1 etc...
dataNames = matrix("0", nrow = nrow(data), ncol = 1, byrow = TRUE)
for (i in 1:nrow(dataNames)) {
dataNames[i, ] = paste(String, i - 1 + startingValue, sep = "") # sep="" means that there is no space between w and the number
}
rownames(data) = c(dataNames)
return (data)
}
NamingCols = function(String, data, startingValue) {
dataNames = matrix("0", nrow = 1, ncol = ncol(data), byrow = TRUE)
for (i in 1:ncol(dataNames)) {
dataNames[, i] = paste(String, i - 1 + startingValue, sep = "") # sep="" means that there is no space between w and the number
}
colnames(data) = c(dataNames)
return (data)
}
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data/New_Data.xlsx")
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="") + #no axes labels
scale_color_discrete(name="Legend")
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
#J√©r√¥me Path:
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="") + #no axes labels
scale_color_discrete(name="Legend")
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
spEvolution = BinominalEvolution(coreData$SP_500)
colnames(spEvolution) = "spEvolution"
# Graph of the S&P Evolution (cumulative)
cumulativeSP = CumulativeSum(spEvolution) #CumulativeSum(spEvolution[!is.na(spEvolution)])
ggplot(cumulativeSP, aes(x=time(cumulativeSP))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=cumulativeSP,colour = "cumulativeSP")) +
labs(x="Time ", y="") + #no axes labels
scale_color_discrete(name="Legend")
View(cumulativeSP)
View(spEvolution)
View(coreData)
size(coreData)
length(coreData)
height(coreData)
nrow(coreData)
coreData["2003-01-02":nrow(coreData),]
View(coreData)
coreData["2003-01-02"]
View(coreData)
coreData["2003-01-02":"2018-03-27",]
coreData["2003-01-02":"2018-03-27",]
coreData["2003-01-02"]
View(coreData)
nrow(coreData["2003-01-02"])
coreData["2003-01-02","2018-03-27"]
coreData[c("2003-01-02","2018-03-27"),]
coreData = coreData[c("2003-01-02":"2018-03-27"),]
coreData = coreData[c("2003-01-02":"2017-03-27"),]
View(coreData)
nrow(coreData)
coreData(2003-01-02)
row(coreData["2003-01-02"])
(coreData["2003-01-02"])
order((coreData["2003-01-02"]))
View(coreData)
coreData[30,]
coreData[45,]
coreData[60,]
coreData[80,]
coreData[75,]
coreData[76,]
coreData[77,]
nrow(coreData)
coreData = coreData[77:3889,]
#J√©r√¥me Path:
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
View(coreData)
coreData = coreData["2003-01-02/",]
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="") + #no axes labels
scale_color_discrete(name="Legend")
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="") + #no axes labels
scale_color_discrete(name="Legend")
View(coreData)
#J√©r√¥me Path:
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
coreData_year = split(coreData_year, f="years")
core_Data
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
coreData_year= core_Data
coreData_year= coreData
coreData_ = split(coreData_year, f="years")
View(coreData_year)
#setwd("~/Desktop/MBF Second Semester/Research Seminar/Regression")
#setwd("~/Users/Michal/Dropbox/UNISG/16. Research Seminar/New_Data.csv")
#install.packages("TTR")
# Opening the core data file
# Michal Path:
#csvFilePathCoreData = "/Users/Michal/Dropbox/UNISG/16. Research Seminar/4. Data/New_Data.csv"
#coreData = read.csv(file = csvFilePathCoreData, # path of the file
#                   header = TRUE, # include the headers
#                  sep = ",") # How the data is separated
#coreData[coreData == ""] <- NA # replace all empty spaces with NA =====> J'arrive pas √† ouvrir a modifer les colones en CSV
#J√©r√¥me Path:
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
coreData_year= coreData
#setwd("~/Desktop/MBF Second Semester/Research Seminar/Regression")
#setwd("~/Users/Michal/Dropbox/UNISG/16. Research Seminar/New_Data.csv")
#install.packages("TTR")
# Opening the core data file
# Michal Path:
#csvFilePathCoreData = "/Users/Michal/Dropbox/UNISG/16. Research Seminar/4. Data/New_Data.csv"
#coreData = read.csv(file = csvFilePathCoreData, # path of the file
#                   header = TRUE, # include the headers
#                  sep = ",") # How the data is separated
#coreData[coreData == ""] <- NA # replace all empty spaces with NA =====> J'arrive pas √† ouvrir a modifer les colones en CSV
#J√©r√¥me Path:
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
coreData_year= coreData
coreData_year = split(coreData_year, f="years")
View(coreData_year)
View(coreData)
# https://machinelearningmastery.com/normalize-standardize-time-series-data-python/
# https://vitalflux.com/data-science-scale-normalize-numeric-data-using-r/
# Personal notes:
# 1) What's nice about logistic regression is that we can decide to invest only on those days we have 99.9% certainty.
# 2) We need to make sure there is no tail risk. i.e. if you invest with 99.9% certainty and you earn only 1.- but with 0.01% chance you loose 1m.-, it's not great
# Importing Libraries & Usefull functions: --------------------------------------------------------------------------------------------------------------
library(xts)
library(zoo)
library(ggplot2)
library(TTR) #Technical Trading Rule
library(gridExtra) #Allow to place 2 graphs on the same grids
library(tseries)
library(readxl)
# Usefull functions: own code
BinominalEvolution = function (x){
for (i in 1:length(x)) {
if (i == length(x)) { # When we get to the last data entry, the output is always NA because we cannot compare it to a future value. Without this, there is an error message
x[i, ] = NA
} else if (is.na(x[i+1, ]) || is.na(x[i, ])) { # If comparing with a NA, the output is automatically NA.
x[i, ] = NA
} else if (coredata(x[i+1, ]) > coredata(x[i, ])) {
x[i, ] = 1
} else {
x[i, ] = 0
}
}
return (x)
}
WeightedMovingAverageTS = function (x, n) { # The function takes two inputs: x = the timeseries that is weighted, n = the amount of days of the weighting
divisor = 0
y = x
for (q in 1:n) { # This part calculates the divisor (i.e. the denominator of the weighted sum)
divisor = divisor + q
}
for (l in 1:length(x)) { # This part calculates the weighted sum
weightedSum = 0
if (l < n) {
y[l, ] = NA
} else {
for (i in 1:n) {
weightedSum = weightedSum + coredata(x[l - i + 1]) * (n - i + 1)
}
y[l, ] = weightedSum
}
}
return (y/divisor) # The function outputs a weighted timeseries
}
normalize <- function(x) {
return ((x - min(x))/(max(x) - min(x)))
}
CumulativeSum <- function(x) {
sum = 0
for (i in 1:nrow(x)) {
sum = sum + coredata(x[i,])
x[i,] = sum
}
return(x)
}
# Defining two functions to name data structures
NamingRows = function(String, data, startingValue) {
# Input Variables:
# String        = value in "" that will be the name that will be iterated
# data          = data structure that will have a new name for rows
# startingValue = allows to start with 0 or 1 etc...
dataNames = matrix("0", nrow = nrow(data), ncol = 1, byrow = TRUE)
for (i in 1:nrow(dataNames)) {
dataNames[i, ] = paste(String, i - 1 + startingValue, sep = "") # sep="" means that there is no space between w and the number
}
rownames(data) = c(dataNames)
return (data)
}
NamingCols = function(String, data, startingValue) {
dataNames = matrix("0", nrow = 1, ncol = ncol(data), byrow = TRUE)
for (i in 1:ncol(dataNames)) {
dataNames[, i] = paste(String, i - 1 + startingValue, sep = "") # sep="" means that there is no space between w and the number
}
colnames(data) = c(dataNames)
return (data)
}
# Part 1: Creating the dataFrame-----------------------------------------------------------------------------------------------------
#setwd("~/Desktop/MBF Second Semester/Research Seminar/Regression")
#setwd("~/Users/Michal/Dropbox/UNISG/16. Research Seminar/New_Data.csv")
#install.packages("TTR")
# Opening the core data file
# Michal Path:
#csvFilePathCoreData = "/Users/Michal/Dropbox/UNISG/16. Research Seminar/4. Data/New_Data.csv"
#coreData = read.csv(file = csvFilePathCoreData, # path of the file
#                   header = TRUE, # include the headers
#                  sep = ",") # How the data is separated
#coreData[coreData == ""] <- NA # replace all empty spaces with NA =====> J'arrive pas √† ouvrir a modifer les colones en CSV
#J√©r√¥me Path:
setwd("~/Dropbox/16. Research Seminar/4. Data/4.1 New_Data")
csvFilePathCoreData= ("~/Dropbox/16. Research Seminar/4. Data/New_Data.csv")
coreData <- read_excel("~/Dropbox/16. Research Seminar/4. Data/New_Data.xlsx")
# OPTIONAL: Truncating the size for testing
coreData = coreData[1:nrow(coreData),] #Missing value in 2010-2011 => start in 2012
# Create a Timeseries of coreData indexed by date
coreData$Time = as.Date(coreData$Time, format = "%d.%m.%Y") # Bug: output pour les ann√©es c'est 0010 √† la place de 2010.
coreData = xts(coreData[, 2:ncol(coreData)], order.by = coreData$Time)
#Select Data from 2003:
coreData = coreData["2003-01-02/",]
#Graph of the SP 500
ggplot(coreData, aes(x=time(coreData))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=coreData$SP_500,colour = "SP_500")) +
labs(x="Time ", y="Points") + #no axes labels
scale_color_discrete(name="Legend")
spEvolution = BinominalEvolution(coreData$SP_500)
colnames(spEvolution) = "spEvolution"
# Graph of the S&P Evolution (cumulative)
cumulativeSP = CumulativeSum(spEvolution) #CumulativeSum(spEvolution[!is.na(spEvolution)])
ggplot(cumulativeSP, aes(x=time(cumulativeSP))) + #aes() creates a mapping of variables to various parts of the plot
geom_line(aes(y=cumulativeSP,colour = "cumulativeSP")) +
labs(x="Time ", y="") + #no axes labels
scale_color_discrete(name="Legend")
View(spEvolution)
cumulativeSP_count= cumulativeSP
cumulativeSP_count = split(cumulativeSP_count, f="years")
lapply(count(cumulativeSP_count))
lapply(cumulativeSP_count, fun=count)
lapply(cumulativeSP_count, FUN = =count)
lapply(cumulativeSP_count, FUN =count)
lapply(cumulativeSP_count, FUN = mean)
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
lapply(spEvolution_count, FUN = mean)
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_count =lapply(spEvolution_count, FUN = mean)
View(spEvolution_count)
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results =lapply(spEvolution_count, FUN = mean)
spEvolution_results
spEvolution_results = lapply(spEvolution_count, FUN = count)
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
count(spEvolution_count)
count(spEvolution_count)
table(spEvolution_count)
spEvolution_results = lapply(spEvolution_count, FUN = table)
spEvolution_results
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = lapply(spEvolution_count, FUN = table)
display(spEvolution_results)
displays(spEvolution_results)
spEvolution_results = lapply(spEvolution_count, FUN = table)
View(spEvolution_results)
View(spEvolution_count)
View(spEvolution)
spEvolution_results
spEvolution_results$year
spEvolution_results
spEvolution_results = apply(spEvolution_count, FUN = table)
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = apply(spEvolution_count, FUN = table)
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = lapply(spEvolution_count, FUN = table)
spEvolution_results
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = sapply(spEvolution_count, FUN = table)
spEvolution_results
View(spEvolution_results)
colnames(spEvolution_results)=c("2003","2004","2005","2006","2007","2008","2009","2010",
"2011","2012","2013","2014","2015","2016","2017","2018")
spEvolution_results
sum(spEvolution_results)
sum(spEvolution_results,2)
apply(spEvolution_results,2, sum)
spEvolution_results[3,]= apply(spEvolution_results,2, sum)
spEvolution_results[3,]= sapply(spEvolution_results,2, sum)
b=apply(spEvolution_results,2, sum)
spEvolution_results= spEvolution_results+apply(spEvolution_results,2, sum)
spEvolution_results
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = sapply(spEvolution_count, FUN = table)
colnames(spEvolution_results)=c("2003","2004","2005","2006","2007","2008","2009","2010",
"2011","2012","2013","2014","2015","2016","2017","2018")
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = sapply(spEvolution_count, FUN = table)
colnames(spEvolution_results)=c("2003","2004","2005","2006","2007","2008","2009","2010",
"2011","2012","2013","2014","2015","2016","2017","2018")
spEvolution_results[3,]= apply(spEvolution_results,2, sum)
apply(spEvolution_results,2, sum)
colnames(spEvolution_results)=c("2003","2004","2005","2006","2007","2008","2009","2010",
"2011","2012","2013","2014","2015","2016","2017","2018")
b=apply(spEvolution_results,2, sum)
spEvolution_results = [c(spEvolution_results,b),]
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = sapply(spEvolution_count, FUN = table)
colnames(spEvolution_results)=c("2003","2004","2005","2006","2007","2008","2009","2010",
"2011","2012","2013","2014","2015","2016","2017","2018")
b=apply(spEvolution_results,2, sum)
spEvolution_results = c(spEvolution_results,b)
spEvolution_results
spEvolution_count= spEvolution
spEvolution_count = split(spEvolution_count, f="years")
spEvolution_results = sapply(spEvolution_count, FUN = table)
colnames(spEvolution_results)=c("2003","2004","2005","2006","2007","2008","2009","2010",
"2011","2012","2013","2014","2015","2016","2017","2018")
apply(spEvolution_results,2, sum)
spEvolution_results
